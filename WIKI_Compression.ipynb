{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import glob\n",
    "import torch\n",
    "import pylab\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import unicodedata\n",
    "import string\n",
    "import time\n",
    "import math\n",
    "import matplotlib.ticker as ticker\n",
    "import torch.utils.data as data_utils\n",
    "import shutil\n",
    "import pdb\n",
    "\n",
    "\n",
    "import torch.multiprocessing as mp\n",
    "from multiprocessing import set_start_method\n",
    "import pickle\n",
    "torch.manual_seed(1)\n",
    "\n",
    "try:\n",
    "    set_start_method('spawn')\n",
    "except RuntimeError:\n",
    "    pass\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper functions\n",
    "\n",
    "### File IO\n",
    "def find_files(path): return glob.glob(path)\n",
    "\n",
    "def read_lines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read() # remove newline\n",
    "    return lines\n",
    "\n",
    "\n",
    "def ids2string(ids):\n",
    "    return \"\".join(index_to_char[i] for i in ids.numpy())\n",
    "    \n",
    "\n",
    "### Data Preprocessing\n",
    "### (seq, batch, n_letter)\n",
    "def ids2tensor(ids):\n",
    "    length = ids.shape[0]\n",
    "    tensor = np.zeros((1, length, n_letters), dtype=np.float32)\n",
    "    for li in range(length):\n",
    "        id = ids[li]\n",
    "        tensor[0][li][id] = 1 ## (batch, seq, n_letters)\n",
    "    return torch.Tensor(tensor).view(length, 1, -1)\n",
    "\n",
    "def string2tensor(string):\n",
    "    length = len(string)\n",
    "    tensor = np.zeros((1, length, n_letters), dtype=np.float32)\n",
    "    for li in range(length):\n",
    "        letter = string[li]\n",
    "        tensor[0][li][char_to_index[letter]] = 1 ## (batch, seq, n_letters)\n",
    "    return torch.Tensor(tensor).view(length, 1, -1)\n",
    "\n",
    "def string2ids(string):\n",
    "    ids = torch.LongTensor(len(string))\n",
    "    for i, c in enumerate(string):\n",
    "        ids[i] = char_to_index[c]\n",
    "    return ids\n",
    "\n",
    "## return batched input tensor and target tensor\n",
    "def get_batch(idx, sequence, batch_size=1):\n",
    "    inputs = torch.cat([ids2tensor(ids[i:i+sequence]) \n",
    "                        for i in range(idx, min(idx + batch_size, data_size-sequence))], dim=1)\n",
    "    \n",
    "    targets = torch.LongTensor(\n",
    "            [\n",
    "                [ids[j] for j in range(i+1, i+sequence+1)]\n",
    "                for i in range(idx, min(idx + batch_size, data_size-sequence))\n",
    "            ]\n",
    "        ) \n",
    "        # list of list of target long number\n",
    "    \n",
    "    return inputs.pin_memory().cuda(non_blocking=True), targets.pin_memory().cuda(non_blocking=True)\n",
    "\n",
    "\n",
    "### checkpoint \n",
    "def save_checkpoint(state, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    print (\"saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Loading\n",
    "TEXT_PATH = 'enwik8'\n",
    "\n",
    "lines = \"\"\n",
    "for filename in find_files(TEXT_PATH):\n",
    "    lines = read_lines(filename)\n",
    "\n",
    " #list(set(lines))\n",
    "\n",
    "with open(\"all_letters\", \"rb\") as f:   # Unpickling\n",
    "    all_letters = pickle.load(f)\n",
    "\n",
    "with open(\"wiki_ids\", \"rb\") as f:   # Unpickling\n",
    "    ids = pickle.load(f)\n",
    "ids = torch.LongTensor(ids)\n",
    "    \n",
    "    \n",
    "data_size, n_letters = len(lines), len(all_letters)\n",
    "\n",
    "char_to_index = {ch : i for i, ch in enumerate(all_letters)}\n",
    "index_to_char = {i : ch for i, ch in enumerate(all_letters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dictionary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-0194292442f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Dictionary' is not defined"
     ]
    }
   ],
   "source": [
    "import dictionary\n",
    "\n",
    "\n",
    "Dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Models\n",
    "### input: (seq,  batch, input_size)\n",
    "### hidden: (num_layers * direction, batch, hidden_size)\n",
    "\n",
    "class PredictionNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(PredictionNetwork, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        \n",
    "        ## Weights\n",
    "        self.lstm1 = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=1)\n",
    "        self.lstm2 = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=1)\n",
    "        self.lstm3 = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=1)\n",
    "        self.lstm2input = nn.Linear(hidden_size + input_size, input_size)\n",
    "        self.lstm3input = nn.Linear(hidden_size + input_size, input_size)\n",
    "        \n",
    "        self.h2o = nn.Linear(hidden_size * 3, output_size)\n",
    "        \n",
    "    def forward(self, input, hiddens):\n",
    "        # LSTM input of shape (seq_len, batch, input_size)\n",
    "        # outputs: (seq_len, batch, num_directions * hidden_size)\n",
    "        [h1, h2, h3] = hiddens\n",
    "        \n",
    "        outputs1, _ = self.lstm1(input, h1)\n",
    "        # cat then linear transform\n",
    "        # Switch batch and sequence dimension ?? \n",
    "        input = self.lstm2input(torch.cat((input, outputs1), 2))\n",
    "        outputs2, _ = self.lstm2(input, h2)\n",
    "        \n",
    "        input = self.lstm3input(torch.cat((input, outputs2), 2))\n",
    "        outputs3, _ = self.lstm3(input, h3)\n",
    "        \n",
    "        outputs = self.h2o(torch.cat((outputs1, outputs2, outputs3), 2))\n",
    "        ## correct ?? \n",
    "        \n",
    "        outputs = F.log_softmax(outputs, 2)\n",
    "        return outputs\n",
    "    \n",
    "    def initHidden(self, layer=1, use_gpu=True):\n",
    "        hidden_layers = []\n",
    "        for i in range(0, layer): \n",
    "            h = Variable(torch.randn(1, self.batch_size, self.hidden_size)).pin_memory()\n",
    "            c = Variable(torch.randn(1, self.batch_size, self.hidden_size)).pin_memory()\n",
    "            if use_gpu:\n",
    "                h = h.to(device)\n",
    "                c = c.to(device)\n",
    "            hidden_layers.append(\n",
    "                (h,c)\n",
    "            )\n",
    "        return hidden_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 512\n",
    "input_size = n_letters\n",
    "output_size = n_letters\n",
    "\n",
    "\n",
    "batch_size = 50 ## batch size too big may cause CUDNN_STATUS_EXECUTION_FAILED\n",
    "sequence = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_checkpoint = True\n",
    "new_model = False\n",
    "\n",
    "\n",
    "### Define Model\n",
    "\n",
    "#adhoc\n",
    "model = PredictionNetwork(n_letters, hidden_size, n_letters, batch_size).cuda()\n",
    "checkpoint = torch.load('checkpoint.pth.tar')\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "###\n",
    "\n",
    "if new_model:\n",
    "    model = PredictionNetwork(n_letters, hidden_size, n_letters, batch_size).to(device)\n",
    "\n",
    "model.batch_size = batch_size\n",
    "\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(np.exp(preds)).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "\n",
    "def sample_text(test_model, ids, temperature=1.0, max_sample_length=100):\n",
    "    if ids.shape[0] != sequence:\n",
    "        print (\"line length doesnt match sequence, break\")\n",
    "        return\n",
    "\n",
    "    input = ids2tensor(ids.cpu()).view(sequence, 1, -1).pin_memory().cuda()\n",
    "    \n",
    "    string = ids2string(ids.cpu())\n",
    "    output_string = string\n",
    "    print (\"Starting with : \" + string)\n",
    "    \n",
    "    origin_batch_size = test_model.batch_size\n",
    "    test_model.batch_size = 1\n",
    "    \n",
    "    print_every = 50\n",
    "    for i in range(max_sample_length):\n",
    "        hiddens = test_model.initHidden(layer=3, use_gpu=True)\n",
    "        outputs = test_model(input, hiddens)\n",
    "        topi = sample(outputs[-1][0].data.cpu().numpy(), temperature)\n",
    "        \n",
    "        if topi == n_letters - 1:\n",
    "            break\n",
    "        else:\n",
    "            letter = all_letters[topi]\n",
    "            string = string[1:] + letter\n",
    "            output_string += letter\n",
    "        \n",
    "        input = string2tensor(string).view(sequence, 1, -1).pin_memory().cuda()\n",
    "        \n",
    "        if i % print_every == 0 and i > 0:\n",
    "            print (\"In Progress {} / {},  Takes {} seconds.\".format(i, max_sample_length, time.time() - start))\n",
    "        \n",
    "    print (\"Generating Text: \\n\")\n",
    "    test_model.batch_size = origin_batch_size\n",
    "    return output_string\n",
    "\n",
    "\n",
    "start_idx = 500\n",
    "string_ids_start_with = ids[start_idx:start_idx+sequence]\n",
    "\n",
    "start = time.time()\n",
    "print(sample_text(model, string_ids_start_with, temperature=0.3, max_sample_length=300)) \n",
    "end = time.time()\n",
    "print (\"\\n Finished ! Takes {} seconds \".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = ids.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Training\n",
    "\n",
    "batch_size = 300\n",
    "model.batch_size = batch_size\n",
    "\n",
    "###\n",
    "\n",
    "ids = ids.cpu().pin_memory().cuda(non_blocking=True).contiguous()\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "criterion = nn.NLLLoss().to(device)\n",
    "max_clip_norm = 2\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "from_checkpoint = True\n",
    "start_epoch = 0\n",
    "start_iter = 0\n",
    "\n",
    "\n",
    "\n",
    "if from_checkpoint:\n",
    "    print(\"=> loading checkpoint \")\n",
    "    checkpoint = torch.load('checkpoint.pth.tar')\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    start_iter = checkpoint['iter']\n",
    "\n",
    "\n",
    "### Training\n",
    "epochs = 3\n",
    "print_every = 50\n",
    "plot_every = 50\n",
    "save_every = 2000\n",
    "sample_every = 2000\n",
    "\n",
    "#### sampling string\n",
    "start_idx = 0\n",
    "string_ids_start_with = ids[start_idx:start_idx+sequence]\n",
    "\n",
    "def train(model, epoch):\n",
    "    global start_epoch\n",
    "    global start_iter\n",
    "    \n",
    "    \n",
    "    ### book keeping\n",
    "    all_losses = []\n",
    "    total_loss = 0\n",
    "    start = time.time()\n",
    "    \n",
    "    iters = int(data_size / batch_size)\n",
    "    \n",
    "    if from_checkpoint is False:\n",
    "        start_iter = 0\n",
    "    else:\n",
    "        from_checkpoint is False\n",
    "    \n",
    "    hiddens = model.initHidden(layer=3, use_gpu=True)\n",
    "    for iter in range(start_iter, iters):\n",
    "        train_start = time.time()\n",
    "        \n",
    "        inputTensor, targetTensor = get_batch(iter * batch_size, sequence, batch_size)\n",
    "        \n",
    "        if inputTensor.shape[1] < batch_size:\n",
    "            print (\"{} not enough samples for batch, break\".format(inputTensor.shape[0]))\n",
    "            break\n",
    "\n",
    "       \n",
    "        hiddens = repackage_hidden(hiddens)\n",
    "        \n",
    "        output, loss = train_batch(model, inputTensor, targetTensor, hiddens)\n",
    "        total_loss += loss\n",
    "        #del inputTensor, targetTensor, output\n",
    "        \n",
    "        \n",
    "        ##### Tracking\n",
    "        if iter % print_every == 0 and iter > 0:\n",
    "            print (\"Epoch : {}, Iteration {} / {}, Loss per {} :  {}, Takes {} Seconds\".format(epoch+1, iter, iters, print_every,  loss, time.time() - start))\n",
    "            start = time.time()\n",
    "\n",
    "        if iter % plot_every == 0 and iter > 0:\n",
    "            all_losses.append(total_loss / plot_every)\n",
    "            total_loss = 0\n",
    "            \n",
    "        if iter % sample_every == 0 and iter > 0:\n",
    "            print(sample_text(model, string_ids_start_with, temperature=1, max_sample_length=100))    \n",
    "\n",
    "        if iter % save_every == 0 and iter > 0: \n",
    "            save_checkpoint({\n",
    "                'epoch': epoch,\n",
    "                'iter': iter,   \n",
    "                'all_losses': all_losses,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'optimizer' : optimizer.state_dict(),\n",
    "            })\n",
    "        ##### \n",
    "        print (\"train {}\".format(time.time() - train_start))\n",
    "        \n",
    "        \n",
    "    return all_losses\n",
    "\n",
    "\n",
    "# outputs: (seq_len, batch, n_letters)\n",
    "# target_tensor (batch, seq)\n",
    "def train_batch(model, input_tensor, target_tensor, hiddens):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    outputs = model(input_tensor, hiddens)\n",
    "    \n",
    "    \n",
    "    loss = 0\n",
    "    target_tensor = target_tensor.view(sequence, batch_size) #(sequence, batch)\n",
    "    \n",
    "    for i in range(0, sequence):\n",
    "        loss += criterion(outputs[i],  target_tensor[i])\n",
    "    \n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm(model.parameters(), max_clip_norm)\n",
    "    optimizer.step()\n",
    "\n",
    "    return outputs, loss.item() / batch_size\n",
    "\n",
    "print (\"Start Training\") \n",
    "\n",
    "\n",
    "\n",
    "# set CUDA_LAUNCH_BLOCKING = 0 to do async operation\n",
    "torch.backends.cudnn.enabled = True\n",
    "if from_checkpoint is False:\n",
    "    start_epoch = 0\n",
    "    \n",
    "def get_batch(idx, sequence, batch_size=1):\n",
    "    inputs = torch.cat([ids2tensor(ids[i:i+sequence]) \n",
    "                        for i in range(idx, min(idx + batch_size, data_size-sequence))], dim=1)\n",
    "    \n",
    "    targets = torch.LongTensor(\n",
    "            [\n",
    "                [ids[j] for j in range(i+1, i+sequence+1)]\n",
    "                for i in range(idx, min(idx + batch_size, data_size-sequence))\n",
    "            ]\n",
    "        ) \n",
    "        # list of list of target long number\n",
    "    return inputs.pin_memory().cuda(non_blocking=True).contiguous(), targets.pin_memory().cuda(non_blocking=True).contiguous()\n",
    "\n",
    "\n",
    "def repackage_hidden(h):\n",
    "    \"\"\"Wraps hidden states in new Tensors, to detach them from their history.\"\"\"\n",
    "    if isinstance(h, torch.Tensor):\n",
    "        return h.detach()\n",
    "    else:\n",
    "        return tuple(repackage_hidden(v) for v in h)\n",
    "\n",
    "    \n",
    "    \n",
    "start = time.time()\n",
    "for epoch_iter in range(start_epoch, epochs):\n",
    "    print (\"Start Training Epoch \", epoch_iter+1) \n",
    "    \n",
    "    # train\n",
    "    train(model, epoch_iter)\n",
    "    \n",
    "    # valid\n",
    "\n",
    "end = time.time()\n",
    "print (\"Training finished ! Takes {} seconds \".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### char RNN paper https://arxiv.org/pdf/1308.0850.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_losses = checkpoint['all_losses']\n",
    "#losses = [float(l.cpu().numpy()) for l in all_losses]\n",
    "#plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-880fd548bc9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
